{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=\"mbv1_1.0_12_90_68.4.tflite\")\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "stuff = interpreter.get_tensor_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Const',\n",
       "  'index': 0,\n",
       "  'shape': array([1, 1, 3], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'ConstantFolding/truediv_recip',\n",
       "  'index': 1,\n",
       "  'shape': array([1, 1, 3], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'float_image_input',\n",
       "  'index': 2,\n",
       "  'shape': array([  1, 224, 224,   3], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/Pad',\n",
       "  'index': 3,\n",
       "  'shape': array([  1, 226, 226,   3], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/Pad/paddings',\n",
       "  'index': 4,\n",
       "  'shape': array([4, 2], dtype=int32),\n",
       "  'dtype': numpy.int32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/Pad_1',\n",
       "  'index': 5,\n",
       "  'shape': array([  1, 114, 114,  64], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/Pad_1/paddings',\n",
       "  'index': 6,\n",
       "  'shape': array([4, 2], dtype=int32),\n",
       "  'dtype': numpy.int32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/Pad_2',\n",
       "  'index': 7,\n",
       "  'shape': array([  1,  58,  58, 128], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/Pad_2/paddings',\n",
       "  'index': 8,\n",
       "  'shape': array([4, 2], dtype=int32),\n",
       "  'dtype': numpy.int32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/Pad_3',\n",
       "  'index': 9,\n",
       "  'shape': array([  1,  30,  30, 256], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/Pad_3/paddings',\n",
       "  'index': 10,\n",
       "  'shape': array([4, 2], dtype=int32),\n",
       "  'dtype': numpy.int32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/Pad_4',\n",
       "  'index': 11,\n",
       "  'shape': array([  1,  16,  16, 512], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/Pad_4/paddings',\n",
       "  'index': 12,\n",
       "  'shape': array([4, 2], dtype=int32),\n",
       "  'dtype': numpy.int32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/Relu',\n",
       "  'index': 13,\n",
       "  'shape': array([  1, 112, 112,  32], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/Relu_1',\n",
       "  'index': 14,\n",
       "  'shape': array([  1, 112, 112,  32], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/Relu_10',\n",
       "  'index': 15,\n",
       "  'shape': array([  1,  28,  28, 256], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/Relu_11',\n",
       "  'index': 16,\n",
       "  'shape': array([  1,  14,  14, 256], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/Relu_12',\n",
       "  'index': 17,\n",
       "  'shape': array([  1,  14,  14, 512], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/Relu_13',\n",
       "  'index': 18,\n",
       "  'shape': array([  1,  14,  14, 512], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/Relu_14',\n",
       "  'index': 19,\n",
       "  'shape': array([  1,  14,  14, 512], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/Relu_15',\n",
       "  'index': 20,\n",
       "  'shape': array([  1,  14,  14, 512], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/Relu_16',\n",
       "  'index': 21,\n",
       "  'shape': array([  1,  14,  14, 512], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/Relu_17',\n",
       "  'index': 22,\n",
       "  'shape': array([  1,  14,  14, 512], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/Relu_18',\n",
       "  'index': 23,\n",
       "  'shape': array([  1,  14,  14, 512], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/Relu_19',\n",
       "  'index': 24,\n",
       "  'shape': array([  1,  14,  14, 512], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/Relu_2',\n",
       "  'index': 25,\n",
       "  'shape': array([  1, 112, 112,  64], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/Relu_20',\n",
       "  'index': 26,\n",
       "  'shape': array([  1,  14,  14, 512], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/Relu_21',\n",
       "  'index': 27,\n",
       "  'shape': array([  1,  14,  14, 512], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/Relu_22',\n",
       "  'index': 28,\n",
       "  'shape': array([  1,  14,  14, 512], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/Relu_23',\n",
       "  'index': 29,\n",
       "  'shape': array([  1,   7,   7, 512], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/Relu_24',\n",
       "  'index': 30,\n",
       "  'shape': array([   1,    7,    7, 1024], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/Relu_25',\n",
       "  'index': 31,\n",
       "  'shape': array([   1,    7,    7, 1024], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/Relu_26',\n",
       "  'index': 32,\n",
       "  'shape': array([   1,    7,    7, 1024], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/Relu_3',\n",
       "  'index': 33,\n",
       "  'shape': array([ 1, 56, 56, 64], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/Relu_4',\n",
       "  'index': 34,\n",
       "  'shape': array([  1,  56,  56, 128], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/Relu_5',\n",
       "  'index': 35,\n",
       "  'shape': array([  1,  56,  56, 128], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/Relu_6',\n",
       "  'index': 36,\n",
       "  'shape': array([  1,  56,  56, 128], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/Relu_7',\n",
       "  'index': 37,\n",
       "  'shape': array([  1,  28,  28, 128], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/Relu_8',\n",
       "  'index': 38,\n",
       "  'shape': array([  1,  28,  28, 256], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/Relu_9',\n",
       "  'index': 39,\n",
       "  'shape': array([  1,  28,  28, 256], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/contraction_1x1_0/convolution_bias',\n",
       "  'index': 40,\n",
       "  'shape': array([64], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/contraction_1x1_0/weights/masked_weight',\n",
       "  'index': 41,\n",
       "  'shape': array([64,  1,  1, 32], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/contraction_1x1_1/convolution_bias',\n",
       "  'index': 42,\n",
       "  'shape': array([128], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/contraction_1x1_1/weights/masked_weight',\n",
       "  'index': 43,\n",
       "  'shape': array([128,   1,   1,  64], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/contraction_1x1_10/convolution_bias',\n",
       "  'index': 44,\n",
       "  'shape': array([512], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/contraction_1x1_10/weights/masked_weight',\n",
       "  'index': 45,\n",
       "  'shape': array([512,   1,   1, 512], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/contraction_1x1_11/convolution_bias',\n",
       "  'index': 46,\n",
       "  'shape': array([1024], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/contraction_1x1_11/weights/masked_weight',\n",
       "  'index': 47,\n",
       "  'shape': array([1024,    1,    1,  512], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/contraction_1x1_12/convolution_bias',\n",
       "  'index': 48,\n",
       "  'shape': array([1024], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/contraction_1x1_12/weights/masked_weight',\n",
       "  'index': 49,\n",
       "  'shape': array([1024,    1,    1, 1024], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/contraction_1x1_2/convolution_bias',\n",
       "  'index': 50,\n",
       "  'shape': array([128], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/contraction_1x1_2/weights/masked_weight',\n",
       "  'index': 51,\n",
       "  'shape': array([128,   1,   1, 128], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/contraction_1x1_3/convolution_bias',\n",
       "  'index': 52,\n",
       "  'shape': array([256], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/contraction_1x1_3/weights/masked_weight',\n",
       "  'index': 53,\n",
       "  'shape': array([256,   1,   1, 128], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/contraction_1x1_4/convolution_bias',\n",
       "  'index': 54,\n",
       "  'shape': array([256], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/contraction_1x1_4/weights/masked_weight',\n",
       "  'index': 55,\n",
       "  'shape': array([256,   1,   1, 256], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/contraction_1x1_5/convolution_bias',\n",
       "  'index': 56,\n",
       "  'shape': array([512], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/contraction_1x1_5/weights/masked_weight',\n",
       "  'index': 57,\n",
       "  'shape': array([512,   1,   1, 256], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/contraction_1x1_6/convolution_bias',\n",
       "  'index': 58,\n",
       "  'shape': array([512], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/contraction_1x1_6/weights/masked_weight',\n",
       "  'index': 59,\n",
       "  'shape': array([512,   1,   1, 512], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/contraction_1x1_7/convolution_bias',\n",
       "  'index': 60,\n",
       "  'shape': array([512], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/contraction_1x1_7/weights/masked_weight',\n",
       "  'index': 61,\n",
       "  'shape': array([512,   1,   1, 512], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/contraction_1x1_8/convolution_bias',\n",
       "  'index': 62,\n",
       "  'shape': array([512], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/contraction_1x1_8/weights/masked_weight',\n",
       "  'index': 63,\n",
       "  'shape': array([512,   1,   1, 512], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/contraction_1x1_9/convolution_bias',\n",
       "  'index': 64,\n",
       "  'shape': array([512], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/contraction_1x1_9/weights/masked_weight',\n",
       "  'index': 65,\n",
       "  'shape': array([512,   1,   1, 512], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/depthwise_nxn_0/depthwise_bias',\n",
       "  'index': 66,\n",
       "  'shape': array([32], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/depthwise_nxn_0/depthwise_weights/read',\n",
       "  'index': 67,\n",
       "  'shape': array([ 1,  3,  3, 32], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/depthwise_nxn_1/depthwise_bias',\n",
       "  'index': 68,\n",
       "  'shape': array([64], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/depthwise_nxn_1/depthwise_weights/read',\n",
       "  'index': 69,\n",
       "  'shape': array([ 1,  3,  3, 64], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/depthwise_nxn_10/depthwise_bias',\n",
       "  'index': 70,\n",
       "  'shape': array([512], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/depthwise_nxn_10/depthwise_weights/read',\n",
       "  'index': 71,\n",
       "  'shape': array([  1,   3,   3, 512], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/depthwise_nxn_11/depthwise_bias',\n",
       "  'index': 72,\n",
       "  'shape': array([512], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/depthwise_nxn_11/depthwise_weights/read',\n",
       "  'index': 73,\n",
       "  'shape': array([  1,   3,   3, 512], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/depthwise_nxn_12/depthwise_bias',\n",
       "  'index': 74,\n",
       "  'shape': array([1024], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/depthwise_nxn_12/depthwise_weights/read',\n",
       "  'index': 75,\n",
       "  'shape': array([   1,    3,    3, 1024], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/depthwise_nxn_2/depthwise_bias',\n",
       "  'index': 76,\n",
       "  'shape': array([128], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/depthwise_nxn_2/depthwise_weights/read',\n",
       "  'index': 77,\n",
       "  'shape': array([  1,   3,   3, 128], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/depthwise_nxn_3/depthwise_bias',\n",
       "  'index': 78,\n",
       "  'shape': array([128], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/depthwise_nxn_3/depthwise_weights/read',\n",
       "  'index': 79,\n",
       "  'shape': array([  1,   3,   3, 128], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/depthwise_nxn_4/depthwise_bias',\n",
       "  'index': 80,\n",
       "  'shape': array([256], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/depthwise_nxn_4/depthwise_weights/read',\n",
       "  'index': 81,\n",
       "  'shape': array([  1,   3,   3, 256], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/depthwise_nxn_5/depthwise_bias',\n",
       "  'index': 82,\n",
       "  'shape': array([256], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/depthwise_nxn_5/depthwise_weights/read',\n",
       "  'index': 83,\n",
       "  'shape': array([  1,   3,   3, 256], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/depthwise_nxn_6/depthwise_bias',\n",
       "  'index': 84,\n",
       "  'shape': array([512], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/depthwise_nxn_6/depthwise_weights/read',\n",
       "  'index': 85,\n",
       "  'shape': array([  1,   3,   3, 512], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/depthwise_nxn_7/depthwise_bias',\n",
       "  'index': 86,\n",
       "  'shape': array([512], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/depthwise_nxn_7/depthwise_weights/read',\n",
       "  'index': 87,\n",
       "  'shape': array([  1,   3,   3, 512], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/depthwise_nxn_8/depthwise_bias',\n",
       "  'index': 88,\n",
       "  'shape': array([512], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/depthwise_nxn_8/depthwise_weights/read',\n",
       "  'index': 89,\n",
       "  'shape': array([  1,   3,   3, 512], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/depthwise_nxn_9/depthwise_bias',\n",
       "  'index': 90,\n",
       "  'shape': array([512], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/depthwise_nxn_9/depthwise_weights/read',\n",
       "  'index': 91,\n",
       "  'shape': array([  1,   3,   3, 512], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/final_avg_pool/AvgPool',\n",
       "  'index': 92,\n",
       "  'shape': array([   1,    1,    1, 1024], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/final_dense/MatMul_bias',\n",
       "  'index': 93,\n",
       "  'shape': array([1000], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/final_dense/kernel/read/transpose',\n",
       "  'index': 94,\n",
       "  'shape': array([1000, 1024], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/final_dense_1',\n",
       "  'index': 95,\n",
       "  'shape': array([   1, 1000], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/initial_conv/Conv2D_bias',\n",
       "  'index': 96,\n",
       "  'shape': array([32], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'resnet_model/initial_conv/kernel/read',\n",
       "  'index': 97,\n",
       "  'shape': array([32,  3,  3,  3], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'sub',\n",
       "  'index': 98,\n",
       "  'shape': array([  1, 224, 224,   3], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'truediv',\n",
       "  'index': 99,\n",
       "  'shape': array([  1, 224, 224,   3], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)}]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contraction_1x1_0 (64,)\n",
      "contraction_1x1_1 (128,)\n",
      "contraction_1x1_10 (512,)\n",
      "contraction_1x1_11 (1024,)\n",
      "contraction_1x1_12 (1024,)\n",
      "contraction_1x1_2 (128,)\n",
      "contraction_1x1_3 (256,)\n",
      "contraction_1x1_4 (256,)\n",
      "contraction_1x1_5 (512,)\n",
      "contraction_1x1_6 (512,)\n",
      "contraction_1x1_7 (512,)\n",
      "contraction_1x1_8 (512,)\n",
      "contraction_1x1_9 (512,)\n",
      "depthwise_nxn_0 (32,)\n",
      "depthwise_nxn_1 (64,)\n",
      "depthwise_nxn_10 (512,)\n",
      "depthwise_nxn_11 (512,)\n",
      "depthwise_nxn_12 (1024,)\n",
      "depthwise_nxn_2 (128,)\n",
      "depthwise_nxn_3 (128,)\n",
      "depthwise_nxn_4 (256,)\n",
      "depthwise_nxn_5 (256,)\n",
      "depthwise_nxn_6 (512,)\n",
      "depthwise_nxn_7 (512,)\n",
      "depthwise_nxn_8 (512,)\n",
      "depthwise_nxn_9 (512,)\n",
      "final_dense (1000,)\n",
      "initial_conv (32,)\n"
     ]
    }
   ],
   "source": [
    "bias_tensors_meta = []\n",
    "bias_tensors = []\n",
    "\n",
    "for j in range(len(stuff)):\n",
    "    if \"bias\" in stuff[j]['name']:\n",
    "        bias_tensors_meta.append(stuff[j])\n",
    "        bias_tensors.append(interpreter.get_tensor(j))\n",
    "        name = bias_tensors_meta[-1]['name'].split(\"/\")[1]\n",
    "        print(name, bias_tensors[-1].shape)\n",
    "        \n",
    "        np.save(name + \"_bias.npy\",bias_tensors[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contraction_1x1_0 (64, 1, 1, 32)\n",
      "contraction_1x1_1 (128, 1, 1, 64)\n",
      "contraction_1x1_10 (512, 1, 1, 512)\n",
      "contraction_1x1_11 (1024, 1, 1, 512)\n",
      "contraction_1x1_12 (1024, 1, 1, 1024)\n",
      "contraction_1x1_2 (128, 1, 1, 128)\n",
      "contraction_1x1_3 (256, 1, 1, 128)\n",
      "contraction_1x1_4 (256, 1, 1, 256)\n",
      "contraction_1x1_5 (512, 1, 1, 256)\n",
      "contraction_1x1_6 (512, 1, 1, 512)\n",
      "contraction_1x1_7 (512, 1, 1, 512)\n",
      "contraction_1x1_8 (512, 1, 1, 512)\n",
      "contraction_1x1_9 (512, 1, 1, 512)\n",
      "depthwise_nxn_0 (1, 3, 3, 32)\n",
      "depthwise_nxn_1 (1, 3, 3, 64)\n",
      "depthwise_nxn_10 (1, 3, 3, 512)\n",
      "depthwise_nxn_11 (1, 3, 3, 512)\n",
      "depthwise_nxn_12 (1, 3, 3, 1024)\n",
      "depthwise_nxn_2 (1, 3, 3, 128)\n",
      "depthwise_nxn_3 (1, 3, 3, 128)\n",
      "depthwise_nxn_4 (1, 3, 3, 256)\n",
      "depthwise_nxn_5 (1, 3, 3, 256)\n",
      "depthwise_nxn_6 (1, 3, 3, 512)\n",
      "depthwise_nxn_7 (1, 3, 3, 512)\n",
      "depthwise_nxn_8 (1, 3, 3, 512)\n",
      "depthwise_nxn_9 (1, 3, 3, 512)\n"
     ]
    }
   ],
   "source": [
    "weight_tensors_meta = []\n",
    "weight_tensors = []\n",
    "\n",
    "for j in range(len(stuff)):\n",
    "    if \"weight\" in stuff[j]['name']:\n",
    "        weight_tensors_meta.append(stuff[j])\n",
    "        weight_tensors.append(interpreter.get_tensor(j))\n",
    "        name = weight_tensors_meta[-1]['name'].split(\"/\")[1]\n",
    "        print(name, weight_tensors[-1].shape)\n",
    "        if \"depthwise\" not in name:\n",
    "            np.save(name + \".npy\",weight_tensors[-1].squeeze().transpose())\n",
    "        else:\n",
    "            np.save(name + \".npy\",weight_tensors[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = torch.Tensor(weight_tensors[0].squeeze().transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 32, 1, 1])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groupwise_filters.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3, 3, 32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_tensors[13].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "depthwise_filters = torch.Tensor(weight_tensors[13]).permute(3,0,1,2)\n",
    "groupwise_filters = torch.Tensor(weight_tensors[0]).permute(0,3,1,2)\n",
    "depthwise_bias = torch.Tensor(bias_tensors[13])\n",
    "groupwise_bias = torch.Tensor(bias_tensors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0047193"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_tensors[13][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = torch.Tensor(np.random.normal(size=(1,32,112,112)))\n",
    "\n",
    "intermediate = torch.nn.functional.conv2d(input_image, depthwise_filters, bias=depthwise_bias, stride=1, padding=1, dilation=1, groups=32)\n",
    "intermediate = torch.nn.functional.relu(intermediate)\n",
    "result_2 = torch.nn.functional.linear(torch.squeeze(intermediate).permute(1,2,0).contiguous().view(-1,32).unsqueeze(0),torch.squeeze(groupwise_filters),bias=None)\n",
    "result_1 = torch.nn.functional.conv2d(intermediate,groupwise_filters,bias=groupwise_bias,stride=1,padding=0,dilation=1,groups=1)\n",
    "result_2 = torch.nn.functional.relu(result_2)\n",
    "result_1 = torch.nn.functional.relu(result_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0098)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(result_1) - torch.sum(result_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"input_image.npy\",input_image.squeeze().data.numpy())\n",
    "np.save(\"depthwise_filters.npy\",depthwise_filters.squeeze().data.numpy())\n",
    "np.save(\"result.npy\",np.transpose(result_2.squeeze().data.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = result_2.squeeze().data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.transpose(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.3124201"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[61,12543]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3831,  3.1401, -0.2365,  ..., -0.8050, -0.1198,  0.1245],\n",
       "        [ 0.1245,  1.8276, -2.1608,  ..., -0.0477, -0.0148, -0.2394],\n",
       "        [-0.0652,  0.7686, -0.8525,  ..., -0.5748, -0.0579,  0.3943],\n",
       "        ...,\n",
       "        [-0.7536,  0.3495,  0.3431,  ...,  0.4957, -1.0231, -0.2651],\n",
       "        [-0.7002, -0.6451,  0.9609,  ...,  0.6272,  0.3472, -0.5790],\n",
       "        [-0.0169, -0.6897,  0.1856,  ...,  0.5823,  0.4537, -0.2379]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intermediate.squeeze()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 112, 112])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 27.6783,  13.3509,   2.4749,  ...,   2.0456,  14.0760,  16.8017],\n",
       "          [-17.8845, -20.6757,  -0.1477,  ..., -10.1470,   3.7224,  -7.5688],\n",
       "          [  9.3705,   3.1455, -13.5922,  ...,  18.8626,  13.5485,  10.4557],\n",
       "          ...,\n",
       "          [  1.3922,  -6.2970,  -3.5007,  ...,  -5.7171,   6.1289,  16.2437],\n",
       "          [  0.8641,   2.9974,  -2.1938,  ...,   6.6196, -19.6970, -23.5239],\n",
       "          [ -5.5657,  -6.7367,  -2.7290,  ...,  -3.3473,  18.6799,  14.2540]],\n",
       "\n",
       "         [[-26.0592,  24.4582,  24.6935,  ..., -10.0700, -16.1549,   1.1208],\n",
       "          [ -2.2788,  13.5296, -18.5339,  ...,   3.3453, -13.1331, -11.1933],\n",
       "          [ 14.2997, -12.3467, -21.8211,  ...,  23.3961, -20.3506,   3.8412],\n",
       "          ...,\n",
       "          [ -3.3056, -17.2721,  36.0502,  ...,  12.2551,  26.8922,  -5.6885],\n",
       "          [  1.6112,   6.4582, -11.0355,  ..., -19.4557,  -6.5783, -44.5635],\n",
       "          [  2.2428,  17.1340,  -3.4808,  ...,   5.8531,   9.1191, -10.5080]],\n",
       "\n",
       "         [[ -1.8048,   4.3149,   0.3001,  ...,  -2.0521,   2.8436,  -3.9529],\n",
       "          [ -1.3115,  -1.5751,  -2.4183,  ...,  -0.8014,  -0.2287,  -5.9840],\n",
       "          [  2.7071,  -1.3315,   7.0303,  ...,  -0.4597,  -7.3331,  -2.0337],\n",
       "          ...,\n",
       "          [  2.3393,   0.5954,  -2.6022,  ...,  -0.2433,   0.7719,   2.5578],\n",
       "          [ -5.0148,   4.0513,   2.9885,  ...,  -7.8524,  -0.4524,   5.5811],\n",
       "          [  1.6535,   0.7835,   1.5813,  ...,  -2.1391,   4.8363,  -7.6332]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[  0.7121,  -6.9704,   3.8111,  ...,   5.4334,   1.1944,   5.7682],\n",
       "          [ -4.6059,   1.4771,  -1.2114,  ...,   1.2090,  -5.8075,   4.3345],\n",
       "          [  1.1413,  -4.0859,  -0.4871,  ...,  -6.9349,  11.8252,  -2.1323],\n",
       "          ...,\n",
       "          [ -1.4611,  -2.5021,   2.6067,  ...,   2.6411,   0.6290,  -1.8686],\n",
       "          [  8.5371, -10.5192,   4.3571,  ...,   2.6191,  -2.0575,   3.3760],\n",
       "          [ -4.8348,   4.5999,  -0.3651,  ...,   7.5995,  -0.1831,  -1.3124]],\n",
       "\n",
       "         [[ -6.0586,  -2.6133,   3.4186,  ...,   2.8079,  -6.7461,  -7.0936],\n",
       "          [ -1.3689,   1.4235,  -5.7621,  ...,  -8.1543,   2.9344,   6.5319],\n",
       "          [-12.5553,   7.6774,   9.4049,  ...,  15.3604,   1.2344,  -6.0152],\n",
       "          ...,\n",
       "          [ -9.2046,  -4.8074,   7.0019,  ...,   6.6249,  -0.8627,  -4.0365],\n",
       "          [  2.9153,   7.1841,  -6.0329,  ...,   8.8737,   7.3694, -15.0283],\n",
       "          [  4.8919,  -5.5336,   0.2384,  ..., -11.5105,   0.2560,   7.6817]],\n",
       "\n",
       "         [[ 10.8406,   8.4961,  -7.3745,  ...,   0.3164,  10.8335,   2.2435],\n",
       "          [  3.0343,  -6.2978,   6.9613,  ...,  10.0678,  -3.9931,  -4.6485],\n",
       "          [ 12.9627,  -5.3803, -11.2961,  ..., -22.2860,  -5.9521,   9.2405],\n",
       "          ...,\n",
       "          [ 13.8203,  11.2399, -14.2299,  ..., -15.5621,   2.8334,   1.9468],\n",
       "          [ -5.0200,  -7.5836,   5.4835,  ...,  -8.6329, -11.7161,  11.4766],\n",
       "          [ -6.6028,   7.4370,   1.8634,  ...,  14.9172,  -0.3706,  -5.7627]]]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_in = torch.nn.functional.pad(input_image,(8,8,1,1))\n",
    "np.save(\"padded_input_image.npy\",padded_in.squeeze().data.numpy())\n",
    "padded_out = torch.nn.functional.pad(result_1,(8,8,1,1))\n",
    "np.save(\"padded_result.npy\",padded_out.squeeze().data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 114, 128])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_in.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-8.2532e+00,  2.4404e-01,  2.1567e+00,  ..., -6.3138e+00,\n",
       "            1.5515e+00, -1.4319e+00],\n",
       "          [ 1.0238e+01, -1.9175e+00, -2.1251e+00,  ...,  1.3523e+01,\n",
       "            1.2930e+01,  3.6847e+00],\n",
       "          [-1.8377e+00,  1.4036e+01, -3.4309e+00,  ...,  4.6984e+00,\n",
       "            5.1230e+00, -9.2765e+00],\n",
       "          ...,\n",
       "          [-7.1223e+00,  7.5712e+00,  1.1183e+01,  ..., -3.1568e+00,\n",
       "            3.9006e+00,  9.1621e+00],\n",
       "          [ 9.9815e+00,  1.0439e+00, -1.0966e+01,  ...,  8.8902e+00,\n",
       "           -7.5760e+00, -3.7577e+00],\n",
       "          [-5.4394e+00, -4.6471e+00,  2.2216e+00,  ..., -5.8488e+00,\n",
       "           -5.7052e-01,  1.4504e+00]],\n",
       "\n",
       "         [[ 9.6889e+00, -1.1620e+01, -6.4342e-01,  ..., -1.4074e+01,\n",
       "            5.8309e+00, -2.4467e+00],\n",
       "          [ 1.6686e+01,  2.3070e+01,  2.7790e+01,  ..., -1.5299e+01,\n",
       "            4.1484e-01, -1.0877e+01],\n",
       "          [-7.3470e+00, -2.3827e+01,  1.6164e+01,  ...,  1.1178e+01,\n",
       "            3.7137e+00,  7.5952e+00],\n",
       "          ...,\n",
       "          [-4.5856e+00,  9.5066e+00, -1.4384e+01,  ..., -2.7885e+01,\n",
       "            3.2961e+01, -2.0375e+01],\n",
       "          [ 2.7336e+01,  2.6577e+00,  6.2745e+00,  ...,  7.5861e+01,\n",
       "           -1.1925e+01,  2.5434e+01],\n",
       "          [-4.4691e+00,  2.4801e+01,  9.0334e+00,  ..., -7.1896e+00,\n",
       "           -1.5051e+01,  8.5771e+00]],\n",
       "\n",
       "         [[-1.9528e+00,  1.9544e+00, -1.1265e-01,  ..., -2.6940e+00,\n",
       "            7.9780e-01,  1.6097e+00],\n",
       "          [ 2.0344e+00, -1.2896e+00,  2.7810e+00,  ...,  2.3411e+00,\n",
       "           -8.3969e-01,  3.0641e+00],\n",
       "          [ 5.0008e-01, -3.5336e+00,  1.3906e+00,  ..., -3.0010e+00,\n",
       "            9.4229e-01, -3.2287e+00],\n",
       "          ...,\n",
       "          [-4.7810e-01, -1.0593e+01,  6.0644e+00,  ...,  1.3901e+00,\n",
       "            6.3465e-01, -1.5612e+00],\n",
       "          [ 2.6422e+00,  2.2025e+00, -2.9055e+00,  ..., -7.8674e+00,\n",
       "           -8.3976e-01, -2.2714e+00],\n",
       "          [ 2.5372e+00, -4.5996e+00,  5.7593e+00,  ..., -2.3288e+00,\n",
       "            2.5124e+00,  2.0755e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 3.9496e+00,  1.2730e-01, -4.4802e+00,  ...,  5.0038e+00,\n",
       "            9.2399e-02, -4.2201e+00],\n",
       "          [ 1.9178e+00, -3.9855e+00,  7.5327e-01,  ..., -5.0984e+00,\n",
       "           -4.3864e-01, -4.5307e+00],\n",
       "          [-8.6805e+00,  6.9064e+00, -3.6444e+00,  ...,  2.4568e+00,\n",
       "            2.5288e+00,  5.0692e+00],\n",
       "          ...,\n",
       "          [ 3.1048e+00,  6.7372e+00, -6.5402e+00,  ..., -4.0125e+00,\n",
       "            1.0459e+00,  3.8374e+00],\n",
       "          [-2.4736e+00,  6.1577e+00,  5.8357e-01,  ..., -2.1989e-02,\n",
       "            5.0870e+00, -2.3536e+00],\n",
       "          [-1.9634e+00,  4.5859e+00, -9.7534e-01,  ...,  3.7156e+00,\n",
       "            2.2193e+00, -1.1772e+00]],\n",
       "\n",
       "         [[-1.2515e+01,  1.0756e+01,  1.1436e+01,  ..., -2.6772e+00,\n",
       "            1.8419e+00, -5.0595e+00],\n",
       "          [-2.3091e+00, -1.2027e+00, -1.1242e+01,  ...,  1.8878e+00,\n",
       "           -2.1201e+00, -3.2827e+00],\n",
       "          [ 8.3019e+00,  8.5319e+00, -3.8972e+00,  ..., -1.9588e+01,\n",
       "           -1.2164e+00,  9.3700e+00],\n",
       "          ...,\n",
       "          [-7.2821e+00, -1.7378e+01,  7.9671e+00,  ...,  8.8131e-01,\n",
       "            1.3493e+01, -1.1574e+01],\n",
       "          [ 3.4276e+00,  1.8644e+01, -6.0562e+00,  ...,  3.9637e+00,\n",
       "           -3.3075e+00,  9.1488e+00],\n",
       "          [ 2.4474e+00, -7.8695e+00,  8.5082e+00,  ...,  1.6967e+00,\n",
       "           -3.6201e+00, -3.1488e+00]],\n",
       "\n",
       "         [[ 1.6884e+01, -2.0900e+01, -1.8449e+01,  ..., -1.8179e+00,\n",
       "           -1.0936e+01,  9.5337e+00],\n",
       "          [ 1.1324e+01,  4.1718e+00,  1.3118e+01,  ...,  1.1516e+01,\n",
       "            1.0600e+01,  2.8609e+00],\n",
       "          [-1.6257e+01, -1.7054e+01,  1.0626e+01,  ...,  2.4609e+01,\n",
       "           -8.5917e+00, -1.8807e+01],\n",
       "          ...,\n",
       "          [ 4.6612e+00,  3.0288e+01, -1.5772e+01,  ..., -2.1542e+00,\n",
       "           -1.7999e+01,  1.9475e+01],\n",
       "          [ 3.7187e+00, -3.3349e+01,  1.0686e+01,  ..., -4.9542e+00,\n",
       "            7.9448e+00, -1.0002e+01],\n",
       "          [-5.6012e+00,  1.2766e+01, -1.3154e+01,  ..., -2.2818e+00,\n",
       "            2.2214e+00,  2.1560e+00]]]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
